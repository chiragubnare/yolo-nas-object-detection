# Yolo-nas-object-detection
YOLO-NAS (You Only Look Once Neural Architecture Search) is a state-of-the-art object detection model implemented based on Neural Architecture Search (NAS) technique. This GitHub repository provides an efficient and scalable implementation of YOLO-NAS for real-time object detection tasks.

The YOLO-NAS model is designed to accurately and rapidly detect objects in images or videos by dividing the input image into a grid and predicting bounding boxes and class probabilities for each grid cell. It utilizes a lightweight neural network architecture that achieves high accuracy while maintaining real-time processing speeds.

Python libraries required to implement Yolo-NAS Custom Object Detection Model
- super-gradients==3.1.0
- imutils
- roboflow
- pytube
- nvidia-pyindex
- pytorch-quantization
- torchinfo

The key feature of this repository is the integration of NAS, which enables the automatic search for the optimal architecture for object detection. By leveraging the power of NAS, YOLO-NAS can dynamically adjust its network architecture, optimizing it for specific detection tasks and achieving superior performance compared to manually designed models.

[`Output File of YoloNAS Model`](https://drive.google.com/file/d/1ikb7BmYrAGPSgUZhBlaMmUxjM8YHXtlP/view?usp=sharing)

With YOLO-NAS, you can take advantage of cutting-edge object detection technology, achieving accurate and efficient detection results for a wide range of applications such as autonomous driving, surveillance systems, and robotics.

Feel free to reachout for any doubts, collaboration on Computer Vision Projects
[`LinkedIn`](https://www.linkedin.com/in/chiragubnare/)
[`chiragubnare@gmail.com`](mailto:chiragubnare@gmail.com)
